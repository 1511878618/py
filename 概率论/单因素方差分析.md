# 方差分析 

## 单因素方差分析

实验中，我们要考察的指标为**试验指标**，影响的条件成为**因素**。由于各种因素的影响，使得测试数据结果呈波动状，包含不可控的**随机因素**、人为调控的**可控因素**。

 

**应用条件：**

1、各样本是相互独立的随机样本

2、各样本均来自正态分布总体

3、各样本的总体方差相等，即具有方差齐性

### 原理

**试验参数**

假设因素A有s个水平$A_1，A_2…..，A_s$，每个水平下进行$n_j$次独立试验，样本总数n

![image-20200513134719621](https://file.upyun.biopy.cn/bed/20200513134721.png)

 

 观测变量**总离差平方和** **=** **组间离差平方和** **+** **组内离差平方和**，表述为：**SST=SSA+SSE**。

**组内差异**——测量误差、个体差异

​    **SSE**（误差平方和）各个水平下，样本观察值与样本均值差异的平方和

​    组内自由度 **dfe=n-s**

**组间差异**——不同实验条件处理

​    **SSA**（因素A的效应平方和）各个水平下样本平均值与数据总平均差异的平方和

​    组间自由度 **dfa=s-1**

**均方 = 离差平方和 / 自由度  SA=SSA/dfa  SE=SSE/dfe**

### 方差分析表（ANOVA）

![image-20200513134636736](https://file.upyun.biopy.cn/bed/20200513134639.png)

### 代码实现



![IMG_0178](https://file.upyun.biopy.cn/bed/20200513134431.PNG)

对于该题目，可以看到

- 因素只有1个，采用的机器种类不同代表着因素水平不同。
- 假定除机器这一因素外其余条件都相同
- 为了检验不同水平下，各个$\mu $是否相同

``` python 
import pandas as pd 
from statsmodels.formula.api import ols 
from statsmodels.stats.anava import anova_lm
```

调用上述代码导入方差分析的相关包

再创建这次实验的数据集。以A表示机器这一因素，不同的机器分别用1，2，3来代表相应的水平，它们仅仅作为分组的标签。而该因素的value，则用value这一列来代表。

```python 
group=[1,1,1,1,1,2,2,2,2,2,3,3,3,3,3]
value  =[0.236,0.238,0.248,0.245,0.243,0.257,0.253,0.255,0.254,0.261,0.258,0.264,0.259,0.267,0.262]
#A列表示，机器这一因素
test = pd.DataFrame({'A':group,'value':value})

```

|      |  A   | value |
| :--- | :--: | ----: |
| 0    |  1   | 0.236 |
| 1    |  1   | 0.238 |
| 2    |  1   | 0.248 |
| 3    |  1   | 0.245 |
| 4    |  1   | 0.243 |
| 5    |  2   | 0.257 |
| 6    |  2   | 0.253 |
| 7    |  2   | 0.255 |
| 8    |  2   | 0.254 |
| 9    |  2   | 0.261 |
| 10   |  3   | 0.258 |
| 11   |  3   | 0.264 |
| 12   |  3   | 0.259 |
| 13   |  3   | 0.267 |
| 14   |  3   | 0.262 |

可以看到`test`的运行结果



使用`ols('value~C(A)',test).fit()`

> ols函数主要有2个参数，formula和data
>
> formula指定了：
> 　　　　　　　　①试验结果是哪一列。
> 　　　　　　　　②需要计算的是哪几个因素水平对结果的影响。
> 　　　　　　　　③是否计算交互作用。
>
> 　　formula的类型为字符串，输入格式为如果试验结果的列名为‘value’，假设需要计算的因素的列名为‘A’和‘B’，则示例如下。
>
> ```python  
> # 因素A的水平对结果的影响
> 'value ~ C(A)'
> 
> # 因素A和因素B的水平对结果的影响
> 'value ~ C(A) + C(B)'
> 
> # 因素A和因素B以及A和B的交互作用的水平对结果的影响
> 'value ~ C(A) + C(B) + C(A)*C(B)'
> 
> # 多因素无重复试验，不计算交互作用的影响
> model = ols('value~C(A) + C(B)', data=data[['A', 'B', 'value']]).fit()
> ```
>
> 

```python 
model = ols('value~C(A)',test).fit()

print(anova_lm(model))
```

运行结果如下：

|          |   df |   sum_sq |  mean_sq |         F |   PR(>F) |
| -------: | ---: | -------: | -------: | --------: | -------: |
|     C(A) |  2.0 | 0.001053 | 0.000527 | 32.916667 | 0.000013 |
| Residual | 12.0 | 0.000192 | 0.000016 |       NaN |      NaN |

若假设显著性$\alpha = 0.05$ 则$p\_value = 0.000013 < 0.05 $ 故可以拒绝假设$H_0$ 而接受$H_1$ 

即 因素A下，不同水平对于value有显著的差异。

又或者计算显著性水平为$\alpha$ 时的F值



导入

`from scipy.stats import f`

$\alpha= 0.05$

使用`f.ppf(1-0.05,2,12)`来计算$F_{0.05}(2,12)$

得到$F_{0.05}(2,12) = 3.88 <32.92$ 故拒绝$H_0$

> **总结一下** 
>
> 1. 计算上$\alpha$ 分位数均采用`f.ppf(1-a,n1,n2)` 计算，对于其他分布，采用类似的方法计算
> 2. 计算某个给定的F值计算相应的P_value采用`f.sf(32.92,2,12)`