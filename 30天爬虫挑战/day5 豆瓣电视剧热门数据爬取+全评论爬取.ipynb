{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正文\n",
    "需要学习re和class类的定义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import collections\n",
    "import math \n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class comment(object):\n",
    "    \"\"\"\n",
    "    关于评论的对象\n",
    "    参数：\n",
    "    stars: 推荐程度\n",
    "    content：评论的内容 \n",
    "    time ：评论时间 \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,stars,content,Time,vote):\n",
    "        self.stars = stars\n",
    "        self.content = content\n",
    "        self.Time = Time\n",
    "        self.vote = vote \n",
    "    \n",
    "    def getContent(self):\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tv(object):\n",
    "    \"\"\"\n",
    "    一个以电视剧作为对象的类  \n",
    "    参数：\n",
    "    Dict：指豆瓣爬虫返回的JSON对象，解析化后获得的dict\n",
    "    属性： \n",
    "    title：电视剧题目 \n",
    "    rank：电视剧评分 \n",
    "    information：电视剧的主演等介绍 \n",
    "    introduction：电视剧的剧情简介 \n",
    "    comments：电视剧相关的评论的集合，集合中 是一系列 comment 对象 \n",
    "    url：电视剧对应的豆瓣页面的链接 \n",
    "    cover：电视剧的封面图链接 \n",
    "    \"\"\"\n",
    "    def __init__(self,Dict):\n",
    "        self.title = Dict['title']\n",
    "        self.rank = Dict['rate']\n",
    "        self.information = ''\n",
    "        self.introduction = '' \n",
    "        self.comments = []\n",
    "        self.url = Dict['url']\n",
    "        self.cover = Dict['cover']\n",
    "        \n",
    "        \n",
    "    def showinformation(self):\n",
    "        #print(self.title)\n",
    "        pass\n",
    "    def getInformation(self,headers,downloadAllComments = True,Turns= 5):\n",
    "        \n",
    "        r = requests.get(self.url,headers=headers)\n",
    "        soup = BeautifulSoup(r.text,'html.parser')\n",
    "        self.information = soup.find('div',id='info').text\n",
    "        self.introduction = soup.find('div',class_='related-info').text\n",
    "        if downloadAllComments == True:    \n",
    "            firstStep = soup.find('div',id='comments-section').find('span',class_='pl')\n",
    "            href = firstStep.find('a')['href']\n",
    "            \n",
    "            num = int(re.search(r'[\\d]+',firstStep.text).group(0))#获取总评论数、\n",
    "            #避免评论太多爬取时间过长\n",
    "            if Turns:\n",
    "                RequestsTimes = Turns \n",
    "            else:\n",
    "                RequestsTimes = math.ceil(num/20)\n",
    "                \n",
    "            for once in range(RequestsTimes):\n",
    "                start = once*20 \n",
    "                commentsUrl = href +'&start={}&limit=20&sort=new_score&percent_type='.format(start)\n",
    "                response = requests.get(commentsUrl,headers=headers)\n",
    "                soup1 = BeautifulSoup(response.text,'html.parser')\n",
    "                time.sleep(0.1)\n",
    "                try:\n",
    "                    commentsList = soup1.find('div',class_= 'mod-bd').find_all('div',class_='comment-item')\n",
    "                    for com in commentsList:\n",
    "                        stars = com.find('span',class_=re.compile('rating'))['title']\n",
    "                        Time = com.find('span',class_='comment-time')['title']\n",
    "                        content=com.find('span',class_='short').text\n",
    "                        vote = com.find('span',class_='votes').text\n",
    "                        COM = comment(stars=stars,Time=Time,content=content,vote=vote)\n",
    "                        self.comments.append(COM)\n",
    "                except:\n",
    "                    break \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        \"\"\"\n",
    "        commentsList =soup.find('div',id='hot-comments').find_all('div',class_='comment-item')\n",
    "        for com in commentsList:            \n",
    "            stars = com.find('span',class_=re.compile('rating'))['title']\n",
    "            time = com.find('span',class_='comment-time')['title']\n",
    "            content=com.find('span',class_='short').text\n",
    "            COM = comment(stars=stars,time=time,content=content) \n",
    "            self.comments.append(COM)\n",
    "\n",
    "        \n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class doubanSpider(object):\n",
    "    \"\"\"\n",
    "    豆瓣爬虫，是一个爬取豆瓣电视剧的内容的爬虫，其主要 爬取每一个电视剧的相关介绍及其评论（目前只有热门评论） \n",
    "    参数： \n",
    "    nums：想要爬取的电视剧总数 \n",
    "    \n",
    "    属性：\n",
    "    head ： 爬虫的头部信息 \n",
    "    url\n",
    "    TVList：爬虫获取的所有电视剧的集合，其中的每一项都是tv对象\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,nums):\n",
    "        self.Totalnums = nums\n",
    "        self.head = {\n",
    "  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.113 Safari/537.36',\n",
    "  'Cookie': 'bid=\"bSK74mb3o0U\"; __gads=ID=81316fb8c6d49141:T=1581057714:S=ALNI_MY6rZqhAl57J0nESAyAyXvRgncNxA; douban-fav-remind=1; ll=\"108309\"; gr_user_id=9d59bb85-5727-4d65-b377-18d1313eb1ca; _vwo_uuid_v2=DA4049E15DA0964D449EC0FD2852882E7|f98f0a5b2d5e82a5c914783eb1008f84; __utmz=30149280.1587041896.8.4.utmcsr=google|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); viewed=\"26022002\"; ap_v=0,6.0; __utma=30149280.549375521.1581057714.1587041896.1587105876.9; __utmc=30149280; __utmb=30149280.10.10.1587105876; _pk_ses.100001.4cf6=*; __utma=223695111.1522244183.1587106246.1587106246.1587106246.1; __utmb=223695111.0.10.1587106246; __utmc=223695111; __utmz=223695111.1587106246.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); __yadk_uid=5hqk227SXsAs0mKJ4P6VisbXsOP8syIv; _pk_id.100001.4cf6=76d2769dc72693ea.1587106246.1.1587106446.1587106246.'\n",
    "}\n",
    "        self.url = \"https://movie.douban.com/j/search_subjects?type=tv&tag=热门&sort=recommend&page_limit=20&page_start={}\"\n",
    "        #self.dict = collections.OrderedDict()\n",
    "        self.TVList = []\n",
    "        \n",
    "    def get_List(self):\n",
    "        \n",
    "        TotalTurn = math.ceil(self.Totalnums/20)\n",
    "        \n",
    "        index1 = TotalTurn*20 #总的需要下载的数目\n",
    "        for startNum in range(TotalTurn):\n",
    "            start = startNum*20\n",
    "             \n",
    "            url = self.url.format(start)\n",
    "            r= requests.get(url,headers=self.head)\n",
    "            List = r.json()['subjects']\n",
    "            for i in List:\n",
    "                TV = tv(i)\n",
    "                TV.getInformation(self.head)\n",
    "                self.TVList.append(TV)\n",
    "                time.sleep(0.5)\n",
    "                print('正在爬取：<{}>的相关信息 '.format(TV.title)) \n",
    "            index2 = start+20 # 记录已经下载了多少数据\n",
    "            print('已经完成了{:.2f}%'.format(index2/index1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取：<我是余欢水>的相关信息 \n",
      "正在爬取：<龙岭迷窟>的相关信息 \n",
      "正在爬取：<十八年后的终极告白>的相关信息 \n",
      "正在爬取：<口罩猎人>的相关信息 \n",
      "正在爬取：<重生>的相关信息 \n",
      "正在爬取：<清平乐>的相关信息 \n",
      "正在爬取：<猎狐>的相关信息 \n",
      "正在爬取：<国王：永远的君主>的相关信息 \n",
      "正在爬取：<杀死伊芙 第三季>的相关信息 \n",
      "正在爬取：<夫妻的世界>的相关信息 \n",
      "正在爬取：<鬓边不是海棠红>的相关信息 \n",
      "正在爬取：<民国奇探>的相关信息 \n",
      "正在爬取：<机智医生生活>的相关信息 \n",
      "正在爬取：<叹息桥>的相关信息 \n",
      "正在爬取：<美国夫人>的相关信息 \n",
      "正在爬取：<冰糖炖雪梨>的相关信息 \n",
      "正在爬取：<陈情令>的相关信息 \n",
      "正在爬取：<西部世界 第三季>的相关信息 \n",
      "正在爬取：<那个男人的记忆法>的相关信息 \n",
      "正在爬取：<请回答1988>的相关信息 \n",
      "已经完成了1.00%\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t= doubanSpider(nums = 5)\n",
    "t.get_List()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(user='root', password='iamyourtf618',database='douban')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "1008 (HY000): Can't drop database 'douban'; database doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-870a1f92877a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DROP DATABASE douban'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mysql\\connector\\cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmd_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterfaceError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_have_next_result\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=W0212\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mysql\\connector\\connection.py\u001b[0m in \u001b[0;36mcmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_cmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mServerCmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQUERY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_have_next_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\mysql\\connector\\connection.py\u001b[0m in \u001b[0;36m_handle_result\u001b[1;34m(self, packet)\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_eof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpacket\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;31m# We have a text result set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: 1008 (HY000): Can't drop database 'douban'; database doesn't exist"
     ]
    }
   ],
   "source": [
    "cursor.execute('DROP DATABASE douban')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.4'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.TVList[0].rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
