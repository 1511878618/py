{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import collections\n",
    "import math \n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 4, 15, 0, 0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class comment(object):\n",
    "    \"\"\"\n",
    "    关于评论的对象\n",
    "    参数：\n",
    "    stars: 推荐程度\n",
    "    content：评论的内容 \n",
    "    time ：评论时间 \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,stars,content,time):\n",
    "        self.stars = stars\n",
    "        self.content = content\n",
    "        self.time = time\n",
    "    \n",
    "    def getContent(self):\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tv(object):\n",
    "    \"\"\"\n",
    "    一个以电视剧作为对象的类  \n",
    "    参数：\n",
    "    Dict：指豆瓣爬虫返回的JSON对象，解析化后获得的dict\n",
    "    属性： \n",
    "    title：电视剧题目 \n",
    "    rank：电视剧评分 \n",
    "    information：电视剧的主演等介绍 \n",
    "    introduction：电视剧的剧情简介 \n",
    "    comments：电视剧相关的评论的集合，集合中 是一系列 comment 对象 \n",
    "    url：电视剧对应的豆瓣页面的链接 \n",
    "    cover：电视剧的封面图链接 \n",
    "    \"\"\"\n",
    "    def __init__(self,Dict):\n",
    "        self.title = Dict['title']\n",
    "        self.rank = Dict['rate']\n",
    "        self.information = ''\n",
    "        self.introduction = '' \n",
    "        self.comments = []\n",
    "        self.url = Dict['url']\n",
    "        self.cover = Dict['cover']\n",
    "        \n",
    "        \n",
    "    def showinformation(self):\n",
    "        #print(self.title)\n",
    "        pass\n",
    "    def getInformation(self,headers):\n",
    "        \n",
    "        r = requests.get(self.url,headers=headers)\n",
    "        soup = BeautifulSoup(r.text,'html.parser')\n",
    "        self.information = soup.find('div',id='info').text\n",
    "        self.introduction = soup.find('div',class_='related-info').text\n",
    "        commentsList =soup.find('div',id='hot-comments').find_all('div',class_='comment-item')\n",
    "        for com in commentsList:            \n",
    "            stars = com.find('span',class_=re.compile('rating'))['title']\n",
    "            time = com.find('span',class_='comment-time')['title']\n",
    "            content=com.find('span',class_='short').text\n",
    "            COM = comment(stars=stars,time=time,content=content) \n",
    "            self.comments.append(COM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class doubanSpider(object):\n",
    "    \"\"\"\n",
    "    豆瓣爬虫，是一个爬取豆瓣电视剧的内容的爬虫，其主要 爬取每一个电视剧的相关介绍及其评论（目前只有热门评论） \n",
    "    参数： \n",
    "    nums：想要爬取的电视剧总数 \n",
    "    \n",
    "    属性：\n",
    "    head ： 爬虫的头部信息 \n",
    "    url\n",
    "    TVList：爬虫获取的所有电视剧的集合，其中的每一项都是tv对象\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,nums):\n",
    "        self.Totalnums = nums\n",
    "        self.head = {\n",
    "  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.113 Safari/537.36',\n",
    "  'Cookie': 'bid=\"bSK74mb3o0U\"; __gads=ID=81316fb8c6d49141:T=1581057714:S=ALNI_MY6rZqhAl57J0nESAyAyXvRgncNxA; douban-fav-remind=1; ll=\"108309\"; gr_user_id=9d59bb85-5727-4d65-b377-18d1313eb1ca; _vwo_uuid_v2=DA4049E15DA0964D449EC0FD2852882E7|f98f0a5b2d5e82a5c914783eb1008f84; __utmz=30149280.1587041896.8.4.utmcsr=google|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); viewed=\"26022002\"; ap_v=0,6.0; __utma=30149280.549375521.1581057714.1587041896.1587105876.9; __utmc=30149280; __utmb=30149280.10.10.1587105876; _pk_ses.100001.4cf6=*; __utma=223695111.1522244183.1587106246.1587106246.1587106246.1; __utmb=223695111.0.10.1587106246; __utmc=223695111; __utmz=223695111.1587106246.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); __yadk_uid=5hqk227SXsAs0mKJ4P6VisbXsOP8syIv; _pk_id.100001.4cf6=76d2769dc72693ea.1587106246.1.1587106446.1587106246.'\n",
    "}\n",
    "        self.url = \"https://movie.douban.com/j/search_subjects?type=tv&tag=热门&sort=recommend&page_limit=20&page_start={}\"\n",
    "        #self.dict = collections.OrderedDict()\n",
    "        self.TVList = []\n",
    "        \n",
    "    def get_List(self):\n",
    "        \n",
    "        TotalTurn = math.ceil(num/20)\n",
    "        \n",
    "        index1 = TotalTurn*20 #总的需要下载的数目\n",
    "        for startNum in range(TotalTurn):\n",
    "            \n",
    "            start = startNum*20\n",
    "             \n",
    "            url = self.url.format(start)\n",
    "            r= requests.get(url,headers=self.head)\n",
    "            List = r.json()['subjects']\n",
    "            for i in List:\n",
    "                TV = tv(i)\n",
    "                TV.getInformation(self.head)\n",
    "                self.TVList.append(TV)\n",
    "                time.sleep(0.5)\n",
    "                print('正在爬取：<{}>的相关信息 '.format(TV.title))\n",
    "            \n",
    "            index2 = start+20 # 记录已经下载了多少数据\n",
    "            print('已经完成了{:.2f}%'.format(index2/index1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在爬取我是余欢水的相关信息 \n",
      "正在爬取龙岭迷窟的相关信息 \n",
      "正在爬取公子，我娶定你了的相关信息 \n",
      "正在爬取魔法师 第五季的相关信息 \n",
      "正在爬取藏宝图的相关信息 \n",
      "正在爬取清平乐的相关信息 \n",
      "正在爬取夫妻的世界的相关信息 \n",
      "正在爬取鬓边不是海棠红的相关信息 \n",
      "正在爬取冰糖炖雪梨的相关信息 \n",
      "正在爬取民国奇探的相关信息 \n",
      "正在爬取叹息桥的相关信息 \n",
      "正在爬取杀死伊芙 第三季的相关信息 \n",
      "正在爬取机智医生生活的相关信息 \n",
      "正在爬取假偶天成的相关信息 \n",
      "正在爬取不完美的她的相关信息 \n",
      "正在爬取西部世界 第三季的相关信息 \n",
      "正在爬取陈情令的相关信息 \n",
      "正在爬取青春有你 第二季的相关信息 \n",
      "正在爬取请回答1988的相关信息 \n",
      "正在爬取环形物语的相关信息 \n",
      "已经完成了0.33%\n",
      "正在爬取重生的相关信息 \n",
      "正在爬取那个男人的记忆法的相关信息 \n",
      "正在爬取傲骨之战 第四季的相关信息 \n",
      "正在爬取三千鸦杀的相关信息 \n",
      "正在爬取朋友请听好的相关信息 \n",
      "正在爬取想见你的相关信息 \n",
      "正在爬取成化十四年的相关信息 \n",
      "正在爬取我们的乐队的相关信息 \n",
      "正在爬取人生第一次的相关信息 \n",
      "正在爬取庆余年 第一季的相关信息 \n",
      "正在爬取锦衣之下的相关信息 \n",
      "正在爬取王牌对王牌 第五季的相关信息 \n",
      "正在爬取王国 第二季的相关信息 \n",
      "正在爬取无心法师3的相关信息 \n",
      "正在爬取如果岁月可回头的相关信息 \n",
      "正在爬取龙岭迷窟之最后的搬山道人的相关信息 \n",
      "正在爬取怒晴湘西的相关信息 \n",
      "正在爬取养虎为患的相关信息 \n",
      "正在爬取梨泰院Class的相关信息 \n",
      "正在爬取天气好的话，我会去找你的相关信息 \n",
      "已经完成了0.67%\n",
      "正在爬取半之半的相关信息 \n",
      "正在爬取安家的相关信息 \n",
      "正在爬取全世界最好的你的相关信息 \n",
      "正在爬取我的天才女友 第二季的相关信息 \n",
      "正在爬取你好妈妈，再见！的相关信息 \n",
      "正在爬取鬣狗式生存的相关信息 \n",
      "正在爬取白夜追凶的相关信息 \n",
      "正在爬取今日的猫村小姐的相关信息 \n",
      "正在爬取我们与恶的距离的相关信息 \n",
      "正在爬取机智牢房生活的相关信息 \n",
      "正在爬取风骚律师 第五季的相关信息 \n",
      "正在爬取大宋少年志的相关信息 \n",
      "正在爬取鬼吹灯之精绝古城的相关信息 \n",
      "正在爬取三生三世枕上书的相关信息 \n",
      "正在爬取摩登家庭 第十一季的相关信息 \n",
      "正在爬取歌手·当打之年的相关信息 \n",
      "正在爬取知否知否应是绿肥红瘦的相关信息 \n",
      "正在爬取意大利制造的相关信息 \n",
      "正在爬取非自然死亡的相关信息 \n",
      "正在爬取365：逆转命运的1年的相关信息 \n",
      "已经完成了1.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t= doubanSpider(nums = 33)\n",
    "t.get_List()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'龙岭迷窟'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
